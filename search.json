[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Docker",
    "section": "",
    "text": "This session aims to introduce the use of Docker containers with the goal of using them to effect reproducible computational environments. Such environments are useful for ensuring reproducible research outputs, for example.\nThe practical work in this lesson is primarily aimed at using Docker on your own laptop. Beyond your laptop, software container technologies such as Docker can also be used in the cloud and on high performance computing (HPC) systems. Some of the material in this lesson will be applicable to those environments too."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Introduction to Docker",
    "section": "",
    "text": "This session aims to introduce the use of Docker containers with the goal of using them to effect reproducible computational environments. Such environments are useful for ensuring reproducible research outputs, for example.\nThe practical work in this lesson is primarily aimed at using Docker on your own laptop. Beyond your laptop, software container technologies such as Docker can also be used in the cloud and on high performance computing (HPC) systems. Some of the material in this lesson will be applicable to those environments too."
  },
  {
    "objectID": "index.html#learning-objectives",
    "href": "index.html#learning-objectives",
    "title": "Introduction to Docker",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this workshop, you will know how to:\n\nHave an understanding of what Docker containers are, why they are useful and the common terminology used\nHave a working Docker installation on your local system to allow you to use containers\nUnderstand how to use existing Docker containers for common tasks\nBe able to build your own Docker containers by understanding both the role of a Dockerfile in building containers, and the syntax used in Dockerfiles\nUnderstand how to manage Docker containers on your local system\nAppreciate issues around reproducibility in software, understand how containers can address some of these issues and what the limits to reproducibility using containers are"
  },
  {
    "objectID": "index.html#course-outline",
    "href": "index.html#course-outline",
    "title": "Introduction to Docker",
    "section": "Course Outline",
    "text": "Course Outline\n\n\n\n\nTime\n\n\nLesson\n\n\nQuestions\n\n\n\n\n20\n\n\nIntroducing Containers\n\n\nWhat are containers, and why might they be useful to me?\n\n\n\n\n10\n\n\nIntroducing the Docker Command Line\n\n\nHow do I know Docker is installed and running?How do I interact with Docker?\n\n\n\n\n20\n\n\nExploring and Running Containers\n\n\nHow do I interact with Docker containers and container images on my computer?\n\n\n\n\n10\n\n\nCleaning Up Containers\n\n\nHow do I interact with a Docker container on my computer?How do I manage my containers and container images?\n\n\n\n\n10\n\n\nFinding Containers on Docker Hub\n\n\nWhat is the Docker Hub, and why is it useful?\n\n\n\n\n20\n\n\nCreating Your Own Container Images\n\n\nHow can I make my own Docker container images?How do I document the ‘recipe’ for a Docker container image?\n\n\n\n\n30\n\n\nCreating More Complex Container Images\n\n\nHow can I add local files (e.g. data files) into container images at build time?How can I access files stored on the host system from within a running Docker container?\n\n\n\n\n10\n\n\nExamples of Using Container Images in Practice\n\n\nHow can I use Docker for my own work?\n\n\n\n\n20\n\n\nContainers in Research Workflows: Reproducibility and Granularity\n\n\nHow can I use container images to make my research more reproducible?How do I incorporate containers into my research workflow?"
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "Introduction to Docker",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nYou should have basic familiarity with using a command shell, and the lesson text will at times request that you “open a shell window”, with an assumption that you know what this means.\n\nUnder Linux or macOS it is assumed that you will access a bash shell (usually the default), using your Terminal application.\nUnder Windows, Powershell and Git Bash should allow you to use the Unix instructions. We will also try to give command variants for Windows cmd.exe.\n\nThe lessons will sometimes request that you use a text editor to create or edit files in particular directories. It is assumed that you either have an editor that you know how to use that runs within the working directory of your shell window (e.g. nano), or that if you use a graphical editor, that you can use it to read and write files into the working directory of your shell.\n\n\nWebsite accounts to create\nPlease seek help at the start of the lesson if you have not been able to establish a website account on:\n\nThe Docker Hub. We will use the Docker Hub to download pre-built container images, and for you to upload and download container images that you create, as explained in the relevant lesson episodes.\n\n\n\nFiles to download\nDownload the docker-intro.zip file. Move the downloaded file to your Desktop and unzip it. It should unzip to a folder called docker-intro.\n\n\nSoftware to install\nDocker’s installation experience has steadily improved, however situations will arise in which installing Docker on your computer may not be straightforward unless you have a large amount of technical experience. Workshops try to have helpers on hand that have worked their way through the install process, but do be prepared for some troubleshooting.\nIn most cases, you will need to have administrator rights on the computer in order to install the Docker software. If you are using a computer managed by your organisation and do not have administrator rights, you may be able to get your organisation’s IT staff to install Docker for you. Alternatively your IT support staff may be able to give you remote access to a server that can run Docker commands.\nPlease try to install the appropriate software from the list below depending on the operating system that your computer is running. Do let the workshop organisers know as early as possible if you are unable to install Docker using these instructions, as there may be other options available.\n\nMicrosoft Windows\nYou must have admin rights to run Docker! Some parts of the lesson will work without running as admin but if you are unable to Run as administrator on your machine some elements of this workshop might not work as described.\nIdeally, you will be able to install the Docker Desktop software, following the Docker website’s documentation. Note that the instructions for installing Docker Desktop on Windows 10 Home Edition are different from other versions of Windows 10.\nNote that the above installation instructions highlight a minimum version or “build” that is required to be able to install Docker on your Windows 10 system. See Which version of Windows operating system am I running? for details of how to find out which version/build of Windows 10 you have.\nIf you are unable to follow the above instructions to install Docker Desktop on your Windows system, the final release of the deprecated Docker Toolbox version of Docker for Windows can be downloaded from the releases page of the Docker Toolbox GitHub repository. (Download the .exe file for the Windows installer). Please note that this final release of Docker Toolbox includes an old version of Docker and you are strongly advised not to attempt to use this for any production use. It will, however, enable you to follow along with the lesson material.\n\n\n\n\n\n\nWarning: Git Bash\n\n\n\nIf you are using Git Bash as your terminal on Windows then you should be aware that you may run into issues running some of the commands in this lesson as Git Bash will automatically re-write any paths you specify at the command line into Windows versions of the paths and this will confuse the Docker container you are trying to use. For example, if you enter the command:\ndocker run alpine cat /etc/os-release\nGit Bash will change the /etc/os-release path to C:\\etc\\os-release\\ before passing the command to the Docker container and the container will report an error. If you want to use Git Bash then you can request that this path translation does not take place by adding an extra / to the start of the path. i.e. the command would become:\ndocker run alpine cat //etc/os-release\nThis should suppress the path translation functionality in Git Bash.\n\n\n\n\nApple macOS\nIdeally, you will be able to install the Docker Desktop software, following the Docker website’s documentation. The current version of the Docker Desktop software requires macOS version 10.14 (Mojave) or later.\nIf you already use Homebrew or MacPorts to manage your software, and would prefer to use those tools rather than Docker’s installer, you can do so. For Homebrew, you can run the command brew install --cask docker. Note that you still need to run the Docker graphical user interface once to complete the initial setup, after which time the command line functionality of Docker will become available. The Homebrew install of Docker also requires a minimum macOS version of 10.14. The MacPorts Docker port should support older, as well as the most recent, operating system versions (see the port details), but note that we have not recently tested the Docker installation process via MacPorts.\n\n\nLinux\nThere are too many varieties of Linux to give precise instructions here, but hopefully you can locate documentation for getting Docker installed on your Linux distribution. It may already be installed. If it is not already installed on your system, the Install Docker Engine page provides an overview of supported Linux distributions and pointers to relevant installation information. Alternatively, see:\n\nDocker Engine on CentOS\nDocker Engine on Debian\nDocker Engine on Fedora\nDocker Engine on Ubuntu\n\n\n\n\nVerify Installation\nTo quickly check if the Docker and client and server are working run the following command in a new terminal or ssh session:\n$ docker version\nClient:\n Version:           20.10.2\n API version:       1.41\n Go version:        go1.13.8\n Git commit:        20.10.2-0ubuntu2\n Built:             Tue Mar  2 05:52:27 2021\n OS/Arch:           linux/arm64\n Context:           default\n Experimental:      true\n\nServer:\n Engine:\n  Version:          20.10.2\n  API version:      1.41 (minimum version 1.12)\n  Go version:       go1.13.8\n  Git commit:       20.10.2-0ubuntu2\n  Built:            Tue Mar  2 05:45:16 2021\n  OS/Arch:          linux/arm64\n  Experimental:     false\n containerd:\n  Version:          1.4.4-0ubuntu1\n  GitCommit:        \n runc:\n  Version:          1.0.0~rc95-0ubuntu1~21.04.1\n  GitCommit:        \n docker-init:\n  Version:          0.19.0\n  GitCommit:        \nThe above output shows a successful installation and will vary based on your system. The important part is that the “Client” and the “Server” parts are both working and returns information. It is beyond the scope of this document to debug installation problems but common errors include the user not belonging to the docker group and forgetting to start a new terminal or ssh session.\n\n\nA quick tutorial on copy/pasting file contents from episodes of the lesson\nLet’s say you want to copy text off the lesson website and paste it into a file named myfile in the current working directory of a shell window. This can be achieved in many ways, depending on your computer’s operating system, but routes I have found work for me:\n\nmacOS and Linux: you are likely to have the nano editor installed, which provides you with a very straightforward way to create such a file, just run nano myfile, then paste text into the shell window, and press control+x to exit: you will be prompted whether you want to save changes to the file, and you can type y to say “yes”.\nMicrosoft Windows running cmd.exe shells:\n\ndel myfile to remove myfile if it already existed;\ncopy con myfile to mean what’s typed in your shell window is copied into myfile;\npaste the text you want within myfile into the shell window;\ntype control+z and then press enter to finish copying content into myfile and return to your shell;\nyou can run the command type myfile to check the content of that file, as a double-check.\n\nMicrosoft Windows running PowerShell:\n\nThe cmd.exe method probably works, but another is to paste your file contents into a so-called “here-string” between @' and '@ as in this example that follows (the “&gt;” is the prompt indicator):\n&gt; @'\nSome hypothetical\nfile content that is\n\nsplit over many\n\nlines.\n'@ | Set-Content myfile -encoding ascii"
  },
  {
    "objectID": "index.html#credits-and-acknowledgement",
    "href": "index.html#credits-and-acknowledgement",
    "title": "Introduction to Docker",
    "section": "Credits and Acknowledgement",
    "text": "Credits and Acknowledgement\nThese content were adapted from the following course materials:\n\nThe Carpentries Incubator - Reproducible Computational Environments Using Containers: Introduction to Docker"
  },
  {
    "objectID": "episodes/08-docker-image-examples.html",
    "href": "episodes/08-docker-image-examples.html",
    "title": "Examples of Using Container Images in Practice",
    "section": "",
    "text": "Overview\n\n\n\n\nTeaching: 10\nExercises: 15\nQuestions:\n\nHow can I use Docker for my own work?\n\nObjectives:\n\nUse existing container images and Docker in a research project.\nNow that we have learned the basics of working with Docker container images and containers, let’s apply what we learned to an example workflow.\nYou may choose one or more of the following examples to practice using containers."
  },
  {
    "objectID": "episodes/08-docker-image-examples.html#github-actions-example",
    "href": "episodes/08-docker-image-examples.html#github-actions-example",
    "title": "Examples of Using Container Images in Practice",
    "section": "GitHub Actions Example",
    "text": "GitHub Actions Example\nIn this GitHub Actions example, you can learn more about continuous integration in the cloud and how you can use container images with GitHub to automate repetitive tasks like testing code or deploying websites. Our specific example will show a neat way to build a simple website that goes with any project you might have going.\n\nGitHub Actions\nGitHub Actions provide a means of automating repetitive tasks to support maintaining software projects. Some examples include:\n\nTesting if your software works correctly (Continuous Integration)\nBuilding components for distribution to your users (Continuous Deployment)\nBuilding documentation\n\nThese are tasks that you could do on your own computer, but consider the following cases:\n\nYour software works on your computer, but you forgot to mention this one crucial package that is required for correct operation.\nYour software used to work, but since the last update something broke.\nSomeone else contributed to your package but didn’t run the same version of the document converter: the documentation looks different now.\n\nThese are just some of the bad things that may happen. To address these issues, it is often desirable to have a consistent, controlled environment in which to run these tasks, collectively known as CI/CD. GitHub can perform these actions for you. You configure GitHub Actions by providing a workflow configuration file (in YAML format) that GitHub Actions reads and runs. The tasks are run, behind the scenes, inside Docker containers. If your project is open source, this service is entirely free of charge. Competing platforms have similar services for which the syntax may vary slightly, but they are all grounded in the use of some form of containers (Docker or otherwise). We will demonstrate the use of a Docker container in deploying a small website presenting a GitHub project.\n\n\nBuilding content for deployment via GitHub Pages with Pandoc\nSuppose you have a GitHub project with a README.md file and would like to turn it into HTML to host as a web page via GitHub Pages. A common problem in documenting and testing software is to keep relevant content in a single location. In a GitHub project this location is the README, however it will look a lot more professional if you also have a custom website where people can find downloads, documentation etc. This website could become part of a larger portfolio of all your projects on GitHub.\nIt would be nice if such a page was updated automatically every time you update other parts of the project.\nA fabulous tool for building web content from Markdown files is Pandoc. You could call it the swiss army knife of document conversion: it is very, very versatile. In this instance we will only use its most basic operation. (If you are familiar with RMarkdown: Pandoc is what powers RMarkdown).\n\n\n\n\n\n\nWhy Pandoc?\n\n\n\nThere are other engines that can do this for you, but here are some features that win some people over:\n\nSupports citations (from BibTeX or CSL database)\nRendered equations (using MathJax, optionally numbered)\nCode highlighting\nHighly customizable\n\n\n\nWe take you through the process of creating a project on GitHub from scratch, converting the README.md file to HTML format and then uploading it to a separate gh-pages branch within the GitHub project. First let’s take a look at what the end product will look like. We have a project (example here) with a main branch that includes a README.md file.\n\nWe can use Pandoc to turn this README.md file into a simple static website.\n\nIf we switch to the gh-pages branch in GitHub we can see where this page is hosted from.\n\nOnly index.html and .nojekyll files are present. The .nojekyll file prevents GitHub from processing the repository content with Jekyll, the approach that is used by default when creating a GitHub Pages website. Instead, Pages skips the Jekyll processing stage and simply deploys the content in the specified branch to the GitHub Pages server. So how do we set this up?\n\nCreate a GitHub Project\nCreate a github project with a short README.md. To do this:\n\ngo to github.com and make sure you’re logged in\nclick the green “New” button at the top right and fill out the form to create the new project\nclone the new project to your computer. The instructions for doing so will be shown in the dialog on GitHub, or you can also see Software Carpentry lesson on Version Control with Git, or the example below:\n\ngit clone &lt;your-repo-url&gt;\ncd &lt;repo-name&gt;\n\n\nUsing Pandoc to Create a Website\nNow that we have cloned the repository we can generate the HTML locally using Pandoc.\nPandoc is a universal document converter. It reads and writes between very many different file formats, including many flavours of Markdown, HTML, LaTeX, Word, RTF, rst and many more. We use it to generate static websites from Markdown.\nFirst, let’s download a container with pandoc installed and run it to see what the pandoc version is.\ndocker container run pandoc/core --version\nUnable to find image 'pandoc/core:latest' locally\nlatest: Pulling from pandoc/core\nf84cab65f19f: Pull complete\nf95e84a31132: Pull complete\n5d5ebbd90555: Pull complete\nd084fb969d20: Pull complete\nDigest: sha256:af1d118e3280ffaf6181af5a9f87ef0c010af9b5877053b750be33d0c47cc6ce\nStatus: Downloaded newer image for pandoc/core:latest\npandoc 2.12\nCompiled with pandoc-types 1.22, texmath 0.12.1.1, skylighting 0.10.4,\nciteproc 0.3.0.8, ipynb 0.1.0.1\nUser data directory: /root/.local/share/pandoc\nCopyright (C) 2006-2021 John MacFarlane. Web:  https://pandoc.org\nThis is free software; see the source for copying conditions. There is no\nwarranty, not even for merchantability or fitness for a particular purpose.\nNow, we can run pandoc on our README.md file by including our current directory and the README.md file as part of the docker container run command:\ndocker container run --mount type=bind,source=${PWD},target=/tmp pandoc/core /tmp/README.md\n&lt;h1 id=\"readme-pages\"&gt;readme-pages&lt;/h1&gt;\n&lt;p&gt;Example for generating GitHub.io pages from Readme with Pandoc.&lt;/p&gt;\nHere, the --mount type=bind,source=${PWD},target=/tmp flag says to take the directory at ${PWD} and make it available inside the container as /tmp. Then pandoc can read the source file (README.md) and convert it to HTML. While this HTML is valid, it doesn’t show the complete structure of a standalone HTML document. For that we need to add the --standalone argument to the pandoc command. Also we can redirect the output to create a HTML file in the build directory.\nmkdir -p build\ndocker container run --mount type=bind,source=${PWD},target=/tmp pandoc/core /tmp/README.md --standalone --output=/tmp/build/index.html\n[WARNING] This document format requires a nonempty &lt;title&gt; element.\n  Defaulting to 'README' as the title.\n  To specify a title, use 'title' in metadata or --metadata title=\"...\".\nTo suppress the warning message we may add the following lines at the top of the README.md file:\n---\ntitle: Hello, Pandoc\n---\nOr add the mentioned --metadata title=\"...\" to the command line.\nOnce we’ve made all of these changes, and produced the output we want, we can check it, using this command:\ncat build/index.html\n&lt;!DOCTYPE html&gt;\n&lt;html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"\" xml:lang=\"\"&gt;\n&lt;head&gt;\n  &lt;meta charset=\"utf-8\" /&gt;\n... etc\nWe now have tested our website deployment workflow - given the source files from GitHub, we can use a Docker container and command to generate our website. We now want to automate this process via GitHub Actions.\n\n\nAutomating Deployment on GitHub Actions\nGitHub Actions is a cloud service for automating continuous integration and deployment. This means we can have GitHub build our website and publish it on github.io automatically at every commit.\nGo to the GitHub project page you created earlier and click on “Actions”. Because we have no active workflows yet, we are taken immediately to a menu for creating a new one. We will skip the templates and click on “set up a workflow yourself”. The configuration format is YAML.\nThe first entry is the name of the workflow\nname: Deploy pages\nNext we specify when this workflow is run. In this case: every time content is pushed to the main branch\non:\n  push:\n    branches:\n      - main\nNow we tell GitHub what to do.\njobs:\n  # a free machine-readable name for this job\n  deploy:\n    # Set permissions for this specific job to enable it to write to the gh-pages branch\n    permissions:\n      contents: write\n    # specify the base operating system\n    runs-on: ubuntu-latest\n    steps:\n      # fetch the contents of the repository\n      - name: Checkout repo content\n        uses: actions/checkout@v2\n      - name: Prepare build environment\n        run: |   # multiple Bash commands follow\n          mkdir -p build\n          touch build/.nojekyll\nNow for the Docker bit:\n      - name: Run pandoc\n        # Always specify a version!\n        uses: docker://pandoc/core:2.12\n        with:\n          args: &gt;-  # multi-line argument\n            --standalone\n            --output=build/index.html\n            README.md\n      - name: Deploy on github pages\n        # Use a third-party plugin to upload the content\n        uses: JamesIves/github-pages-deploy-action@4.1.0\n        with:\n          branch: gh-pages\n          folder: build\nWe may recognize the command-line that we had previously. Notice that we don’t need to specify the --mount flag. GitHub Actions arranges the Docker environment such that the files are in the correct location. The last step uploads the build directory to the gh-pages branch.\nNow we should enable GitHub Pages on this repository: go to the “Settings” tab and scroll down to “GitHub Pages”. There we select the root folder in the gh-pages branch. After a few (tens) of seconds the page should be up."
  },
  {
    "objectID": "episodes/08-docker-image-examples.html#using-containers-on-an-hpc-cluster",
    "href": "episodes/08-docker-image-examples.html#using-containers-on-an-hpc-cluster",
    "title": "Examples of Using Container Images in Practice",
    "section": "Using Containers on an HPC Cluster",
    "text": "Using Containers on an HPC Cluster\nIt is possible to run containers on shared computing systems run by a university or national computing center. As a researcher, you can build container images and test containers on your own computer and then run your full-scale computing work on a shared computing system like a high performance cluster or high throughput grid.\nThe catch? Most university and national computing centers do not support running containers with Docker commands, and instead use a similar tool called Singularity or Shifter. However, both of these programs can be used to run containers based on Docker container images, so often people create their container image as a Docker container image, so they can run it using either of Docker or Singularity.\n\n\n\n\n\n\nTip\n\n\n\nYou can find more detail about using Singularity in the singularity-introduction Carpentries workshop.\n\n\nSingularity is a container engine, like Docker. However, unlike Docker, container images are stored as single files called .sif (Singularity Image Format). For a number of reasons, Singularity suits shared High Performance Computing (HPC) environments much better than Docker, so is valuable to learn if you work in these environments. A related tool called singularity is a fork of Singularity that generally has the same command line interface.\n\n\n\n\n\n\nSingularity Command Line Interface\n\n\n\nLike we did with Docker, try to work out what commands Singularity has. Which one do you think is the equivalent of docker run?\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nsingularity run behaves similarly to docker run, but as we will see, the arguments are somewhat different.\n\n\n\n\nRunning Docker Containers\nSince Singularity containers have their own file format, if we have a Docker image we want to run, it first has to be converted. We can do this using singularity pull. For example, we can pull the container we previously pushed to Docker Hub:\nsingularity pull docker://alice/alpine-python\nThis creates a file called alpine_python.sif in our working directory. To run this container, we then use singularity run:\nsingularity run alpine_python.sif\n\n\nSingularity Exec\nIf we want to modify the command run in the container, we have to use singularity exec. For example, to make Python add numbers like in our sum example, we could do:\napptainer exec alpine_python.sif python -c 'print(1 + 1)'\nFor more information, check these additional resources:\n\nIntroduction to Singularity: See the episode titled “Running MPI parallel jobs using Singularity containers”\nContainer Workflows at Pawsey: See the episode titled “Run containers on HPC with Shifter (and Singularity)”\n\n\n\n\n\n\n\nKey Points\n\n\n\n\nThere are many ways you might use Docker and existing container images in your research project.\n\n\n\n\n\n\n← Previous\n\n\nNext →"
  },
  {
    "objectID": "episodes/04-managing-containers.html",
    "href": "episodes/04-managing-containers.html",
    "title": "Cleaning Up Containers",
    "section": "",
    "text": "Overview\n\n\n\n\nTeaching: 10\nExercises: 0\nQuestions:\n\nHow do I interact with a Docker container on my computer?\nHow do I manage my containers and container images?\n\nObjectives:\n\nExplain how to list running and completed containers.\nKnow how to list and remove container images."
  },
  {
    "objectID": "episodes/04-managing-containers.html#removing-images",
    "href": "episodes/04-managing-containers.html#removing-images",
    "title": "Cleaning Up Containers",
    "section": "Removing images",
    "text": "Removing images\nThe container images and their corresponding containers can start to take up a lot of disk space if you don’t clean them up occasionally, so it’s a good idea to periodically remove containers and container images that you won’t be using anymore.\nIn order to remove a specific container image, you need to find out details about the container image, specifically, the “Image ID”. For example, say my laptop contained the following container image:\ndocker image ls\nREPOSITORY       TAG         IMAGE ID       CREATED          SIZE\nhello-world      latest      fce289e99eb9   15 months ago    1.84kB\nYou can remove the container image with a docker image rm command that includes the Image ID, such as:\ndocker image rm fce289e99eb9\nor use the container image name, like so:\ndocker image rm hello-world\nHowever, you may see this output:\nError response from daemon: conflict: unable to remove repository reference \"hello-world\" (must force) - container e7d3b76b00f4 is using its referenced image fce289e99eb9\nThis happens when Docker hasn’t cleaned up some of the previously running containers based on this container image. So, before removing the container image, we need to be able to see what containers are currently running, or have been run recently, and how to remove these."
  },
  {
    "objectID": "episodes/04-managing-containers.html#what-containers-are-running",
    "href": "episodes/04-managing-containers.html#what-containers-are-running",
    "title": "Cleaning Up Containers",
    "section": "What containers are running?",
    "text": "What containers are running?\nWorking with containers, we are going to shift back to the command: docker container. Similar to docker image, we can list running containers by typing:\ndocker container ls\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\nNotice that this command didn’t return any containers because our containers all exited and thus stopped running after they completed their work.\n\n\n\n\n\n\ndocker ps\n\n\n\nThe command docker ps serves the same purpose as docker container ls, and comes from the Unix shell command ps which describes running processes."
  },
  {
    "objectID": "episodes/04-managing-containers.html#what-containers-have-run-recently",
    "href": "episodes/04-managing-containers.html#what-containers-have-run-recently",
    "title": "Cleaning Up Containers",
    "section": "What containers have run recently?",
    "text": "What containers have run recently?\nThere is also a way to list running containers, and those that have completed recently, which is to add the --all/-a flag to the docker container ls command as shown below.\ndocker container ls --all\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                     PORTS               NAMES\n9c698655416a        hello-world         \"/hello\"            2 minutes ago       Exited (0) 2 minutes ago                       zen_dubinsky\n6dd822cf6ca9        hello-world         \"/hello\"            3 minutes ago       Exited (0) 3 minutes ago                       eager_engelbart\n\n\n\n\n\n\nKeeping it clean\n\n\n\nYou might be surprised at the number of containers Docker is still keeping track of. One way to prevent this from happening is to add the --rm flag to docker container run. This will completely wipe out the record of the run container when it exits. If you need a reference to the running container for any reason, don’t use this flag."
  },
  {
    "objectID": "episodes/04-managing-containers.html#how-do-i-remove-an-exited-container",
    "href": "episodes/04-managing-containers.html#how-do-i-remove-an-exited-container",
    "title": "Cleaning Up Containers",
    "section": "How do I remove an exited container?",
    "text": "How do I remove an exited container?\nTo delete an exited container you can run the following command, inserting the CONTAINER ID for the container you wish to remove. It will repeat the CONTAINER ID back to you, if successful.\ndocker container rm 9c698655416a\n9c698655416a\nAn alternative option for deleting exited containers is the docker container prune command. Note that this command doesn’t accept a container ID as an option because it deletes ALL exited containers! Be careful with this command as deleting the container is forever. Once a container is deleted you can not get it back. If you have containers you may want to reconnect to, you should not use this command. It will ask you if to confirm you want to remove these containers, see output below. If successful it will print the full CONTAINER ID back to you for each container it has removed.\ndocker container prune\nWARNING! This will remove all stopped containers.\nAre you sure you want to continue? [y/N] y\nDeleted Containers:\n9c698655416a848278d16bb1352b97e72b7ea85884bff8f106877afe0210acfc\n6dd822cf6ca92f3040eaecbd26ad2af63595f30bb7e7a20eacf4554f6ccc9b2b"
  },
  {
    "objectID": "episodes/04-managing-containers.html#removing-images-for-real-this-time",
    "href": "episodes/04-managing-containers.html#removing-images-for-real-this-time",
    "title": "Cleaning Up Containers",
    "section": "Removing images, for real this time",
    "text": "Removing images, for real this time\nNow that we’ve removed any potentially running or stopped containers, we can try again to delete the hello-world container image.\ndocker image rm hello-world\nUntagged: hello-world:latest\nUntagged: hello-world@sha256:5f179596a7335398b805f036f7e8561b6f0e32cd30a32f5e19d17a3cda6cc33d\nDeleted: sha256:fce289e99eb9bca977dae136fbe2a82b6b7d4c372474c9235adc1741675f587e\nDeleted: sha256:af0b15c8625bb1938f1d7b17081031f649fd14e6b233688eea3c5483994a66a3\nThe reason that there are a few lines of output, is that a given container image may have been formed by merging multiple underlying layers. Any layers that are used by multiple Docker container images will only be stored once. Now the result of docker image ls should no longer include the hello-world container image.\n\n\n\n\n\n\nKey Points\n\n\n\n\ndocker container has subcommands used to interact and manage containers.\ndocker image has subcommands used to interact and manage container images.\ndocker container ls or docker ps can provide information on currently running containers.\n\n\n\n\n\n\n← Previous\n\n\nNext →"
  },
  {
    "objectID": "episodes/03-running-containers.html",
    "href": "episodes/03-running-containers.html",
    "title": "Exploring and Running Containers",
    "section": "",
    "text": "Overview\n\n\n\n\nTeaching: 20\nExercises: 10\nQuestions:\n\nHow do I interact with Docker containers and container images on my computer?\n\nObjectives:\n\nUse the correct command to see which Docker container images are on your computer.\nBe able to download new Docker container images.\nDemonstrate how to start an instance of a container from a container image.\nDescribe at least two ways to execute commands inside a running Docker container.\nLet’s explore our first Docker container. The Docker team provides a simple container image online called hello-world. We’ll start with that one."
  },
  {
    "objectID": "episodes/03-running-containers.html#downloading-docker-images",
    "href": "episodes/03-running-containers.html#downloading-docker-images",
    "title": "Exploring and Running Containers",
    "section": "Downloading Docker images",
    "text": "Downloading Docker images\nThe docker image command is used to interact with Docker container images. You can find out what container images you have on your computer by using the following command (“ls” is short for “list”):\n$ docker image ls\nIf you’ve just installed Docker, you won’t see any container images listed.\nTo get a copy of the hello-world Docker container image from the internet, run this command:\n$ docker image pull hello-world\nYou should see output like this:\nUsing default tag: latest\nlatest: Pulling from library/hello-world\n1b930d010525: Pull complete\nDigest: sha256:f9dfddf63636d84ef479d645ab5885156ae030f611a56f3a7ac7f2fdd86d7e4e\nStatus: Downloaded newer image for hello-world:latest\ndocker.io/library/hello-world:latest\n\n\n\n\n\n\nDocker Hub\n\n\n\nWhere did the hello-world container image come from? It came from the Docker Hub website, which is a place to share Docker container images with other people. More on that in a later episode.\n\n\n\n\n\n\n\n\nExercise: Check on Your Images\n\n\n\nWhat command would you use to see if the hello-world Docker container image had downloaded successfully and was on your computer? Give it a try before checking the solution.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nTo see if the hello-world container image is now on your computer, run:\n$ docker image ls\n\n\nNote that the downloaded hello-world container image is not in the folder where you are in the terminal! (Run ls by itself to check.) The container image is not a file like our normal programs and documents; Docker stores it in a specific location that isn’t commonly accessed, so it’s necessary to use the special docker image command to see what Docker container images you have on your computer."
  },
  {
    "objectID": "episodes/03-running-containers.html#running-the-hello-world-container",
    "href": "episodes/03-running-containers.html#running-the-hello-world-container",
    "title": "Exploring and Running Containers",
    "section": "Running the hello-world container",
    "text": "Running the hello-world container\nTo create and run containers from named Docker container images you use the docker container run command. Try the following docker container run invocation. Note that it does not matter what your current working directory is.\n$ docker container run hello-world\nHello from Docker!\nThis message shows that your installation appears to be working correctly.\n\nTo generate this message, Docker took the following steps:\n 1. The Docker client contacted the Docker daemon.\n 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n    (amd64)\n 3. The Docker daemon created a new container from that image which runs the\n    executable that produces the output you are currently reading.\n 4. The Docker daemon streamed that output to the Docker client, which sent it\n    to your terminal.\n\nTo try something more ambitious, you can run an Ubuntu container with:\n $ docker run -it ubuntu bash\n\nShare images, automate workflows, and more with a free Docker ID:\n https://hub.docker.com/\n\nFor more examples and ideas, visit:\n https://docs.docker.com/get-started/\nWhat just happened? When we use the docker container run command, Docker does three things:\n\n\n\n\n\n\n\n\n1. Starts a Running Container\n2. Performs Default Action\n3. Shuts Down the Container\n\n\n\n\nStarts a running container, based on the container image. Think of this as the “alive” or “inflated” version of the container – it’s actually doing something.\nIf the container has a default action set, it will perform that default action. This could be as simple as printing a message (as above) or running a whole analysis pipeline!\nOnce the default action is complete, the container stops running (or exits). The container image is still there, but nothing is actively running.\n\n\n\nThe hello-world container is set up to run an action by default – namely to print this message.\n\n\n\n\n\n\nUsing docker container run to get the image\n\n\n\nWe could have skipped the docker image pull step; if you use the docker container run command and you don’t already have a copy of the Docker container image, Docker will automatically pull the container image first and then run it."
  },
  {
    "objectID": "episodes/03-running-containers.html#running-a-container-with-a-chosen-command",
    "href": "episodes/03-running-containers.html#running-a-container-with-a-chosen-command",
    "title": "Exploring and Running Containers",
    "section": "Running a container with a chosen command",
    "text": "Running a container with a chosen command\nBut what if we wanted to do something different with the container? The output just gave us a suggestion of what to do – let’s use a different Docker container image to explore what else we can do with the docker container run command. The suggestion above is to use ubuntu, but we’re going to run a different type of Linux, alpine instead because it’s quicker to download.\n\n\n\n\n\n\nRun the Alpine Docker container\n\n\n\nTry downloading the alpine container image and using it to run a container. You can do it in two steps, or one. What are they?\n\n\nWhat happened when you ran the Alpine Docker container?\n$ docker container run alpine\nIf you have never used the alpine Docker container image on your computer, Docker probably printed a message that it couldn’t find the container image and had to download it. If you used the alpine container image before, the command will probably show no output. That’s because this particular container is designed for you to provide commands yourself. Try running this instead:\n$ docker container run alpine cat /etc/os-release\nYou should see the output of the cat /etc/os-release command, which prints out the version of Alpine Linux that this container is using and a few additional bits of information.\n\n\n\n\n\n\nHello World, Part 2\n\n\n\nCan you run a copy of the alpine container and make it print a “hello world” message?\nGive it a try before checking the solution.\n\n\n\n\n\n\n\n\nSolution\n\n\n\nUse the same command as above, but with the echo command to print a message.\n$ docker container run alpine echo 'Hello World'\n\n\nSo here, we see another option – we can provide commands at the end of the docker container run command and they will execute inside the running container."
  },
  {
    "objectID": "episodes/03-running-containers.html#running-containers-interactively",
    "href": "episodes/03-running-containers.html#running-containers-interactively",
    "title": "Exploring and Running Containers",
    "section": "Running containers interactively",
    "text": "Running containers interactively\nIn all the examples above, Docker has started the container, run a command, and then immediately stopped the container. But what if we wanted to keep the container running so we could log into it and test drive more commands? The way to do this is by adding the interactive flags -i and -t (usually combined as -it) to the docker container run command and provide a shell (bash,sh, etc.) as our command. The alpine Docker container image doesn’t include bash so we need to use sh.\n$ docker container run -it alpine sh\n\n\n\n\n\n\nTechnically…\n\n\n\nTechnically, the interactive flag is just -i – the extra -t (combined as -it above) is the “pseudo-TTY” option, a fancy term that means a text interface. This allows you to connect to a shell, like sh, using a command line. Since you usually want to have a command line when running interactively, it makes sense to use the two together.\n\n\nYour prompt should change significantly to look like this:\n/ #\nThat’s because you’re now inside the running container! Try these commands:\n\npwd\nls\nwhoami\necho $PATH\ncat /etc/os-release\n\nAll of these are being run from inside the running container, so you’ll get information about the container itself, instead of your computer. To finish using the container, type exit.\n/ # exit\n\n\n\n\n\n\nPractice Makes Perfect\n\n\n\nCan you find out the version of Ubuntu installed on the ubuntu container image? (Hint: You can use the same command as used to find the version of alpine.)\nCan you also find the apt-get program? What does it do? (Hint: try passing --help to almost any command will give you more information.)\n\n\n\n\n\n\n\n\nSolution 1 – Interactive\n\n\n\nRun an interactive ubuntu container – you can use docker image pull first, or just run it with this command:\n$ docker container run -it ubuntu sh\nOR you can get the bash shell instead\n$ docker container run -it ubuntu bash\nThen try, running these commands\n/# cat /etc/os-release\n/# apt-get --help\nExit when you’re done.\n/# exit\n\n\n\n\n\n\n\n\nSolution 2 – Run commands\n\n\n\nRun a ubuntu container, first with a command to read out the Linux version:\n$ docker container run ubuntu cat /etc/os-release\nThen run a container with a command to print out the apt-get help:\n$ docker container run ubuntu apt-get --help\n\n\n\n\n\n\n\n\nEven More Options\n\n\n\nThere are many more options, besides -it that can be used with the docker container run command! A few of them will be covered in later episodes and we’ll share two more common ones here:\n\n--rm: this option guarantees that any running container is completely removed from your computer after the container is stopped. Without this option, Docker actually keeps the “stopped” container around, which you’ll see in a later episode. Note that this option doesn’t impact the container images that you’ve pulled, just running instances of containers.\n--name=: By default, Docker assigns a random name and ID number to each container instance that you run on your computer. If you want to be able to more easily refer to a specific running container, you can assign it a name using this option."
  },
  {
    "objectID": "episodes/03-running-containers.html#conclusion",
    "href": "episodes/03-running-containers.html#conclusion",
    "title": "Exploring and Running Containers",
    "section": "Conclusion",
    "text": "Conclusion\nSo far, we’ve seen how to download Docker container images, use them to run commands inside running containers, and even how to explore a running container from the inside. Next, we’ll take a closer look at all the different kinds of Docker container images that are out there.\n\n\n\n\n\n\nKey Points\n\n\n\n\nThe docker image pull command downloads Docker container images from the internet.\nThe docker image ls command lists Docker container images that are (now) on your computer.\nThe docker container run command creates running containers from container images and can run commands inside them.\nWhen using the docker container run command, a container can run a default action (if it has one), a user specified action, or a shell to be used interactively.\n\n\n\n\n\n\n← Previous\n\n\nNext →"
  },
  {
    "objectID": "episodes/01-introduction.html",
    "href": "episodes/01-introduction.html",
    "title": "Introducing Containers",
    "section": "",
    "text": "Overview\n\n\n\n\nTeaching: 20\nExercises: 5\nQuestions:\n\nWhat are containers, and why might they be useful to me?\n\nObjectives:\n\nShow how software depending on other software leads to configuration management problems.\nIdentify the problems that software installation can pose for research.\nExplain the advantages of containerization.\nExplain how using containers can solve software configuration problems"
  },
  {
    "objectID": "episodes/01-introduction.html#scientific-software-challenges",
    "href": "episodes/01-introduction.html#scientific-software-challenges",
    "title": "Introducing Containers",
    "section": "Scientific Software Challenges",
    "text": "Scientific Software Challenges\n\n\n\n\n\n\nWhat’s Your Experience?\n\n\n\nTake a minute to think about challenges that you have experienced in using scientific software (or software in general!) for your research. Then, share with your neighbors and try to come up with a list of common gripes or challenges.\n\n\n\n\n\n\n\n\nWhat is a software dependency?\n\n\n\nWe will mention software dependencies a lot in this section of the workshop so it is good to clarify this term up front. A software dependency is a relationship between software components where one component relies on the other to work properly. For example, if a software application uses a library to query a database, the application depends on that library.\n\n\nYou may have come up with some of the following:\n\nyou want to use software that doesn’t exist for the operating system (Mac, Windows, Linux) you’d prefer.\nyou struggle with installing a software tool because you have to install a number of other dependencies first. Those dependencies, in turn, require other things, and so on (i.e. combinatoric explosion).\nthe software you’re setting up involves many dependencies and only a subset of all possible versions of those dependencies actually works as desired.\nyou’re not actually sure what version of the software you’re using because the install process was so circuitous.\nyou and a colleague are using the same software but get different results because you have installed different versions and/or are using different operating systems.\nyou installed everything correctly on your computer but now need to install it on a colleague’s computer/campus computing cluster/etc.\nyou’ve written a package for other people to use but a lot of your users frequently have trouble with installation.\nyou need to reproduce a research project from a former colleague and the software used was on a system you no longer have access to.\n\nA lot of these characteristics boil down to one fact: the main program you want to use likely depends on many, many, different other programs (including the operating system!), creating a very complex, and often fragile system. One change or missing piece may stop the whole thing from working or break something that was already running. It’s no surprise that this situation is sometimes informally termed dependency hell.\n\n\n\n\n\n\nSoftware and Science\n\n\n\nAgain, take a minute to think about how the software challenges we’ve discussed could impact (or have impacted!) the quality of your work. Share your thoughts with your neighbors. What can go wrong if our software doesn’t work?\n\n\nUnsurprisingly, software installation and configuration challenges can have negative consequences for research:\n\nyou can’t use a specific tool at all, because it’s not available or installable.\nyou can’t reproduce your results because you’re not sure what tools you’re actually using.\nyou can’t access extra/newer resources because you’re not able to replicate your software set up.\nothers cannot validate and/or build upon your work because they cannot recreate your system’s unique configuration.\n\nThankfully there are ways to get underneath (a lot of) this mess: containers to the rescue! Containers provide a way to package up software dependencies and access to resources such as files and communications networks in a uniform manner."
  },
  {
    "objectID": "episodes/01-introduction.html#what-is-a-container",
    "href": "episodes/01-introduction.html#what-is-a-container",
    "title": "Introducing Containers",
    "section": "What is a Container?",
    "text": "What is a Container?\nImagine you want to install some research software but don’t want to take the chance of making a mess of your existing system by installing a bunch of additional stuff (libraries/dependencies/etc.). You don’t want to buy a whole new computer because it’s too expensive. What if, instead, you could have another independent filesystem and running operating system that you could access from your main computer, and that is actually stored within this existing computer?\nMore concretely, Docker Inc use the following definition of a container:\n\nA container is a standard unit of software that packages up code and all its dependencies so the application runs reliably from one computing environment to another.\n\nhttps://www.docker.com/resources/what-container/\nThe term container can be usefully considered with reference to shipping containers. Before shipping containers were developed, packing and unpacking cargo ships was time consuming and error prone, with high potential for different clients’ goods to become mixed up. Just like shipping containers keep things together that should stay together, software containers standardize the description and creation of a complete software system: you can drop a container into any computer with the container software installed (the ‘container host’), and it should just work.\n\n\n\n\n\n\nVirtualization\n\n\n\nContainers are an example of what’s called virtualization – having a second virtual computer running and accessible from a main or host computer. Another example of virtualization are virtual machines or VMs. A virtual machine typically contains a whole copy of an operating system in addition to its own filesystem and has to get booted up in the same way a computer would. A container is considered a lightweight version of a virtual machine; underneath, the container is (usually) using the Linux kernel and simply has some flavour of Linux + the filesystem inside."
  },
  {
    "objectID": "episodes/01-introduction.html#what-is-docker",
    "href": "episodes/01-introduction.html#what-is-docker",
    "title": "Introducing Containers",
    "section": "What is Docker?",
    "text": "What is Docker?\nDocker is a tool that allows you to build and run containers. It’s not the only tool that can create containers, but is the one we’ve chosen for this workshop."
  },
  {
    "objectID": "episodes/01-introduction.html#container-images",
    "href": "episodes/01-introduction.html#container-images",
    "title": "Introducing Containers",
    "section": "Container Images",
    "text": "Container Images\nOne final term: while the container is an alternative filesystem layer that you can access and run from your computer, the container image is the ‘recipe’ or template for a container. The container image has all the required information to start up a running copy of the container. A running container tends to be transient and can be started and shut down. The container image is more long-lived, as a definition for the container. You could think of the container image like a cookie cutter – it can be used to create multiple copies of the same shape (or container) and is relatively unchanging, where cookies come and go. If you want a different type of container (cookie) you need a different container image (cookie cutter)."
  },
  {
    "objectID": "episodes/01-introduction.html#putting-the-pieces-together",
    "href": "episodes/01-introduction.html#putting-the-pieces-together",
    "title": "Introducing Containers",
    "section": "Putting the Pieces Together",
    "text": "Putting the Pieces Together\nThink back to some of the challenges we described at the beginning. The many layers of scientific software installations make it hard to install and re-install scientific software – which ultimately, hinders reliability and reproducibility.\nBut now, think about what a container is – a self-contained, complete, separate computer filesystem. What advantages are there if you put your scientific software tools into containers?\nThis solves several of our problems:\n\ndocumentation – there is a clear record of what software and software dependencies were used, from bottom to top.\nportability – the container can be used on any computer that has Docker installed – it doesn’t matter whether the computer is Mac, Windows or Linux-based.\nreproducibility – you can use the exact same software and environment on your computer and on other resources (like a large-scale computing cluster).\nconfigurability – containers can be sized to take advantage of more resources (memory, CPU, etc.) on large systems (clusters) or less, depending on the circumstances.\n\nThe rest of this workshop will show you how to download and run containers from pre-existing container images on your own computer, and how to create and share your own container images."
  },
  {
    "objectID": "episodes/01-introduction.html#use-cases-for-containers",
    "href": "episodes/01-introduction.html#use-cases-for-containers",
    "title": "Introducing Containers",
    "section": "Use cases for containers",
    "text": "Use cases for containers\nNow that we have discussed a little bit about containers – what they do and the issues they attempt to address – you may be able to think of a few potential use cases in your area of work. Some examples of common use cases for containers in a research context include:\n\nUsing containers solely on your own computer to use a specific software tool or to test out a tool (possibly to avoid a difficult and complex installation process, to save your time or to avoid dependency hell).\nCreating a Dockerfile that generates a container image with software that you specify installed, then sharing a container image generated using this Dockerfile with your collaborators for use on their computers or a remote computing resource (e.g. cloud-based or HPC system).\nArchiving the container images so you can repeat analysis/modelling using the same software and configuration in the future – capturing your workflow.\n\n\n\n\n\n\n\nKey Points\n\n\n\n\nAlmost all software depends on other software components to function, but these components have independent evolutionary paths.\nSmall environments that contain only the software that is needed for a given task are easier to replicate and maintain.\nCritical systems that cannot be upgraded, due to cost, difficulty, etc. need to be reproduced on newer systems in a maintainable and self-documented way.\nVirtualization allows multiple environments to run on a single computer.\nContainerization improves upon the virtualization of whole computers by allowing efficient management of the host computer’s memory and storage resources.\nContainers are built from ‘recipes’ that define the required set of software components and the instructions necessary to build/install them within a container image.\nDocker is just one software platform that can create containers and the resources they use.\n\n\n\n\n\n\n \n\n\nNext →"
  },
  {
    "objectID": "episodes/09-reproduciblity.html",
    "href": "episodes/09-reproduciblity.html",
    "title": "Containers in Research Workflows: Reproducibility and Granularity",
    "section": "",
    "text": "Overview\n\n\n\n\nTeaching: 20\nExercises: 5\nQuestions:\n\nHow can I use container images to make my research more reproducible?\nHow do I incorporate containers into my research workflow?\n\nObjectives:\n\nUnderstand how container images can help make research more reproducible.\nUnderstand what practical steps I can take to improve the reproducibility of my research using containers.\nAlthough this workshop is titled “Reproducible computational environments using containers”, so far we have mostly covered the mechanics of using Docker with only passing reference to the reproducibility aspects. In this section, we discuss these aspects in more detail."
  },
  {
    "objectID": "episodes/09-reproduciblity.html#reproducibility",
    "href": "episodes/09-reproduciblity.html#reproducibility",
    "title": "Containers in Research Workflows: Reproducibility and Granularity",
    "section": "Reproducibility",
    "text": "Reproducibility\nBy reproducibility here we mean the ability of someone else (or your future self) being able to reproduce what you did computationally at a particular time (be this in research, analysis or something else) as closely as possible, even if they do not have access to exactly the same hardware resources that you had when you did the original work.\nWhat makes this especially important? With research being increasingly digital in nature, more and more of our research outputs are a result of the use of software and data processing or analysis. With complex software stacks or groups of dependencies often being required to run research software, we need approaches to ensure that we can make it as easy as possible to recreate an environment in which a given research process was undertaken. There many reasons why this matters, one example being someone wanting to reproduce the results of a publication in order to verify them and then build on that research.\nSome examples of why containers are an attractive technology to help with reproducibility include:\n\nThe same computational work can be run seamlessly on different operating systems (e.g. Windows, macOS, Linux).\nYou can save the exact process that you used for your computational work (rather than relying on potentially incomplete notes).\nYou can save the exact versions of software and their dependencies in the container image.\nYou can provide access to legacy versions of software and underlying dependencies which may not be generally available any more.\nDepending on their size, you can also potentially store a copy of key data within the container image.\nYou can archive and share a container image as well as associating a persistent identifier with it, to allow other researchers to reproduce and build on your work."
  },
  {
    "objectID": "episodes/09-reproduciblity.html#sharing-images",
    "href": "episodes/09-reproduciblity.html#sharing-images",
    "title": "Containers in Research Workflows: Reproducibility and Granularity",
    "section": "Sharing images",
    "text": "Sharing images\nAs we have already seen, the Docker Hub provides a platform for sharing container images publicly. Once you have uploaded a container image, you can point people to its public location and they can download and build upon it.\nThis is fine for working collaboratively with container images on a day-to-day basis but the Docker Hub is not a good option for long-term archiving of container images in support of research and publications as:\n\nfree accounts have a limit on how long a container image will be hosted if it is not updated\nit does not support adding persistent identifiers to container images\nit is easy to overwrite tagged container images with newer versions by mistake."
  },
  {
    "objectID": "episodes/09-reproduciblity.html#archiving-and-persistently-identifying-container-images-using-zenodo",
    "href": "episodes/09-reproduciblity.html#archiving-and-persistently-identifying-container-images-using-zenodo",
    "title": "Containers in Research Workflows: Reproducibility and Granularity",
    "section": "Archiving and persistently identifying container images using Zenodo",
    "text": "Archiving and persistently identifying container images using Zenodo\nWhen you publish your work or make it publicly available in some way it is good practice to make container images that you used for computational work available in an immutable, persistent way and to have an identifier that allows people to cite and give you credit for the work you have done. Zenodo is one service that provides this functionality.\nZenodo supports the upload of tar archives and we can capture our Docker container images as tar archives using the docker image save command. For example, to export the container image we created earlier in this lesson:\ndocker image save alice/alpine-python:v1 -o alpine-python.tar\nThese tar container images can become quite large and Zenodo supports uploads up to 50GB so you may need to compress your archive to make it fit on Zenodo using a tool such as gzip (or zip):\ngzip alpine-python.tar\nOnce you have your archive, you can deposit it on Zenodo and this will:\n\nCreate a long-term archive snapshot of your Docker container image which people (including your future self) can download and reuse or reproduce your work.\nCreate a persistent DOI (Digital Object Identifier) that you can cite in any publications or outputs to enable reproducibility and recognition of your work.\n\nIn addition to the archive file itself, the deposit process will ask you to provide some basic metadata to classify the container image and the associated work.\nNote that Zenodo is not the only option for archiving and generating persistent DOIs for container images. There are other services out there – for example, some organizations may provide their own, equivalent, service."
  },
  {
    "objectID": "episodes/09-reproduciblity.html#reproducibility-good-practice",
    "href": "episodes/09-reproduciblity.html#reproducibility-good-practice",
    "title": "Containers in Research Workflows: Reproducibility and Granularity",
    "section": "Reproducibility good practice",
    "text": "Reproducibility good practice\n\nMake use of container images to capture the computational environment required for your work.\nDecide on the appropriate granularity for the container images you will use for your computational work – this will be different for each project/area. Take note of accepted practice from contemporary work in the same area. What are the right building blocks for individual container images in your work?\nDocument what you have done and why – this can be put in comments in the Dockerfile and the use of the container image described in associated documentation and/or publications. Make sure that references are made in both directions so that the container image and the documentation are appropriately linked.\nWhen you publish work (in whatever way) use an archiving and DOI service such as Zenodo to make sure your container image is captured as it was used for the work and that it is assigned a persistent DOI to allow it to be cited and referenced properly.\nMake use of tags when naming your container images, this ensures that if you update the image in future, previous versions can be retained within a container repository to be easily accessed, if this is required.\nA built and archived container image can ensure a persistently bundled set of software and dependecies. However, a Dockerfile provides a lightweight means of storing a container definition that can be used to re-create a container image at a later time. If you’re taking this approach, ensure that you specify software package and dependency versions within your Dockerfile rather than just specifying package names which will generally install the most up-to-date version of a package. This may be incompatible with other elements of your software stack. Also note that storing only a Dockerfile presents reproducibility challenges because required versions of packages may not be available indefinitely, potentially meaning that you’re unable to reproduce the required environment and, hence, the research results."
  },
  {
    "objectID": "episodes/09-reproduciblity.html#container-granularity",
    "href": "episodes/09-reproduciblity.html#container-granularity",
    "title": "Containers in Research Workflows: Reproducibility and Granularity",
    "section": "Container Granularity",
    "text": "Container Granularity\nAs mentioned above, one of the decisions you may need to make when containerising your research workflows is what level of granularity you wish to employ. The two extremes of this decision could be characterized as:\n\nCreate a single container image with all the tools you require for your research or analysis workflow\nCreate many container images each running a single command (or step) of the workflow and use them together\n\nOf course, many real applications will sit somewhere between these two extremes.\n\n\n\n\n\n\nPositives and negatives\n\n\n\nWhat are the advantages and disadvantages of the two approaches to container granularity for research workflows described above? Think about this and write a few bullet points for advantages and disadvantages for each approach in the course Etherpad.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThis is not an exhaustive list but some of the advantages and disadvantages could be:\n\nSingle large container image\n\nAdvantages:\n\nSimpler to document\nFull set of requirements packaged in one place\nPotentially easier to maintain (though could be opposite if working with large, distributed group)\n\nDisadvantages:\n\nCould get very large in size, making it more difficult to distribute\n\nCould use Docker multi-stage build to reduce size\n\nMay end up with same dependency issues within the container image from different software requirements\nPotentially more complex to test\nLess re-useable for different, but related, work\n\n\n\n\nMultiple smaller container images\n\nAdvantages:\n\nIndividual components can be re-used for different, but related, work\nIndividual parts are smaller in size making them easier to distribute\nAvoid dependency issues between different pieces of software\nEasier to test\n\nDisadvantage:\n\nMore difficult to document\nPotentially more difficult to maintain (though could be easier if working with large, distributed group)\nMay end up with dependency issues between component container images if they get out of sync\n\n\n\n\n\n\n\n\n\n\n\n\nNext steps with containers\n\n\n\nNow that we’re at the end of the lesson material, take a moment to reflect on what you’ve learned, how it applies to you, and what to do next.\n\nIn your own notes, write down or diagram your understanding of Docker containers and container images: concepts, commands, and how they work.\nIn the workshop’s shared notes document, write down how you think you might use containers in your daily work. If there’s something you want to try doing with containers right away, what is a next step after this workshop to make that happen?\n\n\n\n\n\n\n\n\n\nKey Points\n\n\n\n\nContainer images allow us to encapsulate the computation (and data) we have used in our research.\nUsing a service such as Docker Hub allows us to easily share computational work we have done.\nUsing container images along with a DOI service such as Zenodo allows us to capture our work and enables reproducibility.\n\n\n\n\n\n\n← Previous"
  },
  {
    "objectID": "episodes/05-docker-hub.html",
    "href": "episodes/05-docker-hub.html",
    "title": "Finding Containers on Docker Hub",
    "section": "",
    "text": "Overview\n\n\n\n\nTeaching: 10\nExercises: 10\nQuestions:\n\nWhat is the Docker Hub, and why is it useful?\n\nObjectives:\n\nUnderstand the importance of container registries such as Docker Hub, quay.io, etc.\nExplore the Docker Hub webpage for a popular Docker container image.\nFind the list of tags for a particular Docker container image.\nIdentify the three components of a container image’s identifier.\nIn the previous episode, we ran a few different containers derived from different container images: hello-world, alpine, and maybe ubuntu. Where did these container images come from? The Docker Hub!"
  },
  {
    "objectID": "episodes/05-docker-hub.html#introducing-the-docker-hub",
    "href": "episodes/05-docker-hub.html#introducing-the-docker-hub",
    "title": "Finding Containers on Docker Hub",
    "section": "Introducing the Docker Hub",
    "text": "Introducing the Docker Hub\nThe Docker Hub is an online repository of container images, a vast number of which are publicly available. A large number of the container images are curated by the developers of the software that they package. Also, many commonly used pieces of software that have been containerized into images are officially endorsed, which means that you can trust the container images to have been checked for functionality, stability, and that they don’t contain malware.\n\n\n\n\n\n\nDocker can be used without connecting to the Docker Hub\n\n\n\nNote that while the Docker Hub is well integrated into Docker functionality, the Docker Hub is certainly not required for all types of use of Docker containers. For example, some organizations may run container infrastructure that is entirely disconnected from the Internet."
  },
  {
    "objectID": "episodes/05-docker-hub.html#exploring-an-example-docker-hub-page",
    "href": "episodes/05-docker-hub.html#exploring-an-example-docker-hub-page",
    "title": "Finding Containers on Docker Hub",
    "section": "Exploring an Example Docker Hub Page",
    "text": "Exploring an Example Docker Hub Page\nAs an example of a Docker Hub page, let’s explore the page for the official Python language container images. The most basic form of containerized Python is in the python container image (which is endorsed by the Docker team). Open your web browser to https://hub.docker.com/_/python to see what is on a typical Docker Hub software page.\nThe top-left provides information about the name, short description, popularity (i.e., more than a billion downloads in the case of this container image), and endorsements.\nThe top-right provides the command to pull this container image to your computer.\nThe main body of the page contains many used headings, such as:\n\nWhich tags (i.e., container image versions) are supported;\nSummary information about where to get help, which computer architectures are supported, etc.;\nA longer description of the container image;\nExamples of how to use the container image; and\nThe license that applies.\n\nThe “How to use the image” section of most container images’ pages will provide examples that are likely to cover your intended use of the container image."
  },
  {
    "objectID": "episodes/05-docker-hub.html#exploring-container-image-versions",
    "href": "episodes/05-docker-hub.html#exploring-container-image-versions",
    "title": "Finding Containers on Docker Hub",
    "section": "Exploring Container Image Versions",
    "text": "Exploring Container Image Versions\nA single Docker Hub page can have many different versions of container images, based on the version of the software inside. These versions are indicated by “tags”. When referring to the specific version of a container image by its tag, you use a colon, :, like this:\nCONTAINER_IMAGE_NAME:TAG\nSo if I wanted to download the python container image, with Python 3.8, I would use this name:\ndocker image pull python:3.8\nBut if I wanted to download a Python 3.6 container image, I would use this name:\ndocker image pull python:3.6\nThe default tag (which is used if you don’t specify one) is called latest.\nSo far, we’ve only seen container images that are maintained by the Docker team. However, it’s equally common to use container images that have been produced by individual owners or organizations. Container images that you create and upload to Docker Hub would fall into this category, as would the container images maintained by organizations like ContinuumIO (the folks who develop the Anaconda Python environment) or community groups like rocker, a group that builds community R container images.\nThe name for these group- or individually-managed container images have this format:\nOWNER/CONTAINER_IMAGE_NAME:TAG\n\n\n\n\n\n\nRepositories\n\n\n\nThe technical name for the contents of a Docker Hub page is a “repository.” The tag indicates the specific version of the container image that you’d like to use from a particular repository. So a slightly more accurate version of the above example is:\nOWNER/REPOSITORY:TAG\n\n\n\n\n\n\n\n\nWhat’s in a name?\n\n\n\nHow would I download the Docker container image produced by the rocker group that has version 3.6.1 of R and the tidyverse installed?\nNote: the container image described in this exercise is large and won’t be used later in this lesson, so you don’t actually need to pull the container image – constructing the correct docker pull command is sufficient.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nFirst, search for rocker in Docker Hub. Then look for their tidyverse container image. You can look at the list of tags, or just guess that the tag is 3.6.1. Altogether, that means that the name of the container image we want to download is:\ndocker image pull rocker/tidyverse:3.6.1"
  },
  {
    "objectID": "episodes/05-docker-hub.html#finding-container-images-on-docker-hub",
    "href": "episodes/05-docker-hub.html#finding-container-images-on-docker-hub",
    "title": "Finding Containers on Docker Hub",
    "section": "Finding Container Images on Docker Hub",
    "text": "Finding Container Images on Docker Hub\nThere are many different container images on Docker Hub. This is where the real advantage of using containers shows up – each container image represents a complete software installation that you can use and access without any extra work!\nThe easiest way to find container images is to search on Docker Hub, but sometimes software pages have a link to their container images from their home page.\nNote that anyone can create an account on Docker Hub and share container images there, so it’s important to exercise caution when choosing a container image on Docker Hub. These are some indicators that a container image on Docker Hub is consistently maintained, functional and secure:\n\nThe container image is updated regularly.\nThe container image associated with a well established company, community, or other group that is well-known.\nThere is a Dockerfile or other listing of what has been installed to the container image.\nThe container image page has documentation on how to use the container image.\n\nIf a container image is never updated, created by a random person, and does not have a lot of metadata, it is probably worth skipping over. Even if such a container image is secure, it is not reproducible and not a dependable way to run research computations.\n\n\n\n\n\n\nWhat container image is right for you?\n\n\n\nFind a Docker container image that’s relevant to you. Take into account the suggestions above of what to look for as you evaluate options. If you’re unsuccessful in your search, or don’t know what to look for, you can use the R or Python container image we’ve already seen.\nOnce you find a container image, use the skills from the previous episode to download the container image and explore it.\n\n\n\n\n\n\n\n\nKey Points\n\n\n\n\nThe Docker Hub is an online repository of container images.\nMany Docker Hub container images are public, and may be officially endorsed.\nEach Docker Hub page about a container image provides structured information and subheadings\nMost Docker Hub pages about container images contain sections that provide examples of how to use those container images.\nMany Docker Hub container images have multiple versions, indicated by tags.\nThe naming convention for Docker container images is: OWNER/CONTAINER_IMAGE_NAME:TAG\n\n\n\n\n\n\n← Previous\n\n\nNext →"
  },
  {
    "objectID": "episodes/07-advanced-containers.html",
    "href": "episodes/07-advanced-containers.html",
    "title": "Creating More Complex Container Images",
    "section": "",
    "text": "Overview\n\n\n\n\nTeaching: 30\nExercises: 30\nQuestions:\n\nHow can I add local files (e.g. data files) into container images at build time?\nHow can I access files stored on the host system from within a running Docker container?\n\nObjectives:\n\nExplain how you can include files within Docker container images when you build them.\nExplain how you can access files on the Docker host from your Docker containers.\nIn order to create and use your own container images, you may need more information than our previous example. You may want to use files from outside the container, that are not included within the container image, either by copying the files into the container image, or by making them visible within a running container from their existing location on your host system. You may also want to learn a little bit about how to install software within a running container or a container image. This episode will look at these advanced aspects of running a container or building a container image. Note that the examples will get gradually more and more complex – most day-to-day use of containers and container images can be accomplished using the first 1–2 sections on this page."
  },
  {
    "objectID": "episodes/07-advanced-containers.html#using-scripts-and-files-from-outside-the-container",
    "href": "episodes/07-advanced-containers.html#using-scripts-and-files-from-outside-the-container",
    "title": "Creating More Complex Container Images",
    "section": "Using scripts and files from outside the container",
    "text": "Using scripts and files from outside the container\nIn your shell, change to the sum folder in the docker-intro folder and look at the files inside.\ncd ~/Desktop/docker-intro/sum\nls\nThis folder has both a Dockerfile and a Python script called sum.py. Let’s say we wanted to try running the script using a container based on our recently created alpine-python container image.\n\n\n\n\n\n\nRunning containers\n\n\n\nQuestion: What command would we use to run Python from the alpine-python container?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe can run a container from the alpine-python container image using:\ndocker container run alice/alpine-python\nWhat happens? Since the Dockerfile that we built this container image from had a CMD entry that specified [\"python3\", \"--version\"], running the above command simply starts a container from the image, runs the python3 --version command and exits. You should have seen the installed version of Python printed to the terminal.\nInstead, if we want to run an interactive Python terminal, we can use docker container run to override the default run command embedded within the container image. So we could run:\ndocker container run -it alice/alpine-python python3\nThe -it tells Docker to set up and interactive terminal connection to the running container, and then we’re telling Docker to run the python3 command inside the container which gives us an interactive Python interpreter prompt. (type exit() to exit!)\n\n\n\nIf we try running the container and Python script, what happens?\ndocker container run alice/alpine-python python3 sum.py\npython3: can't open file '//sum.py': [Errno 2] No such file or directory\n\n\n\n\n\n\nNo such file or directory\n\n\n\nQuestion: What does the error message mean? Why might the Python inside the container not be able to find or open our script?\nThis question is here for you to think about - we explore the answer to this question in the content below.\n\n\nThe problem here is that the container and its filesystem is separate from our host computer’s filesystem. When the container runs, it can’t see anything outside itself, including any of the files on our computer. In order to use Python (inside the container) and our script (outside the container, on our host computer), we need to create a link between the directory on our computer and the container.\nThis link is called a “mount” and is what happens automatically when a USB drive or other external hard drive gets connected to a computer – you can see the contents appear as if they were on your computer.\nWe can create a mount between our computer and the running container by using an additional option to docker container run. We’ll also use the variable ${PWD} which will substitute in our current working directory. The option will look like this\n--mount type=bind,source=${PWD},target=/temp\nWhat this means is: make my current working directory (on the host computer) – the source – visible within the container that is about to be started, and inside this container, name the directory /temp – the target.\n\n\n\n\n\n\nTypes of mounts\n\n\n\nYou will notice that we set the mount type=bind, there are other types of mount that can be used in Docker (e.g. volume and tmpfs). We do not cover other types of mounts or the differences between these mount types in the course as it is more of an advanced topic. You can find more information on the different mount types in the Docker documentation.\n\n\nLet’s try running the command now:\ndocker container run --mount type=bind,source=${PWD},target=/temp alice/alpine-python python3 sum.py\nBut we get the same error!\npython3: can't open file '//sum.py': [Errno 2] No such file or directory\nThis final piece is a bit tricky – we really have to remember to put ourselves inside the container. Where is the sum.py file? It’s in the directory that’s been mapped to /temp – so we need to include that in the path to the script. This command should give us what we need:\ndocker container run --mount type=bind,source=${PWD},target=/temp alice/alpine-python python3 /temp/sum.py\nNote that if we create any files in the /temp directory while the container is running, these files will appear on our host filesystem in the original directory and will stay there even when the container stops.\n\n\n\n\n\n\nOther Commonly Used Docker Run Flags\n\n\n\nDocker run has many other useful flags to alter its function. A couple that are commonly used include -w and -u.\nThe --workdir/-w flag sets the working directory a.k.a. runs the command being executed inside the directory specified. For example, the following code would run the pwd command in a container started from the latest ubuntu image in the /home/alice directory and print /home/alice. If the directory doesn’t exist in the image it will create it.\ndocker container run -w /home/alice/ ubuntu pwd\nThe --user/-u flag lets you specify the username you would like to run the container as. This is helpful if you’d like to write files to a mounted folder and not write them as root but rather your own user identity and group. A common example of the -u flag is --user $(id -u):$(id -g) which will fetch the current user’s ID and group and run the container as that user.\n\n\n\n\n\n\n\n\nExercise: Explore the script\n\n\n\nWhat happens if you use the docker container run command above and put numbers after the script name?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThis script comes from the Python Wiki and is set to add all numbers that are passed to it as arguments.\n\n\n\n\n\n\n\n\n\nExercise: Checking the options\n\n\n\nOur Docker command has gotten much longer! Can you go through each piece of the Docker command above and explain what it does? How would you characterize the key components of a Docker command?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nHere’s a breakdown of each piece of the command above\n\ndocker container run: use Docker to run a container\n--mount type=bind,source=${PWD},target=/temp: connect my current working directory (${PWD}) as a folder inside the container called /temp\nalice/alpine-python: name of the container image to use to run the container\npython3 /temp/sum.py: what commands to run in the container\n\nMore generally, every Docker command will have the form: docker [action] [docker options] [docker container image] [command to run inside]\n\n\n\n\n\n\n\n\n\nExercise: Interactive jobs\n\n\n\nTry using the directory mount option but run the container interactively. Can you find the folder that’s connected to your host computer? What’s inside?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThe docker command to run the container interactively is:\ndocker container run --mount type=bind,source=${PWD},target=/temp -it alice/alpine-python sh\nOnce inside, you should be able to navigate to the /temp folder and see that’s contents are the same as the files on your host computer:\n/# cd /temp\n/# ls\n\n\n\nMounting a directory can be very useful when you want to run the software inside your container on many different input files. In other situations, you may want to save or archive an authoritative version of your data by adding it to the container image permanently. That’s what we will cover next."
  },
  {
    "objectID": "episodes/07-advanced-containers.html#including-your-scripts-and-data-within-a-container-image",
    "href": "episodes/07-advanced-containers.html#including-your-scripts-and-data-within-a-container-image",
    "title": "Creating More Complex Container Images",
    "section": "Including your scripts and data within a container image",
    "text": "Including your scripts and data within a container image\nOur next project will be to add our own files to a container image – something you might want to do if you’re sharing a finished analysis or just want to have an archived copy of your entire analysis including the data. Let’s assume that we’ve finished with our sum.py script and want to add it to the container image itself.\nIn your shell, you should still be in the sum folder in the docker-intro folder.\npwd\n/Users/yourname/Desktop/docker-intro/sum\nLet’s add a new line to the Dockerfile we’ve been using so far to create a copy of sum.py. We can do so by using the COPY keyword.\nCOPY sum.py /home\nThis line will cause Docker to copy the file from your computer into the container’s filesystem. Let’s build the container image like before, but give it a different name:\ndocker image build -t alice/alpine-sum .\n\n\n\n\n\n\nThe Importance of Command Order in a Dockerfile\n\n\n\nWhen you run docker image build it executes the build in the order specified in the Dockerfile. This order is important for rebuilding and you typically will want to put your RUN commands before your COPY commands.\nDocker builds the layers of commands in order. This becomes important when you need to rebuild container images. If you change layers later in the Dockerfile and rebuild the container image, Docker doesn’t need to rebuild the earlier layers but will instead used a stored (called “cached”) version of those layers.\nFor example, in an instance where you wanted to copy multiply.py into the container image instead of sum.py. If the COPY line came before the RUN line, it would need to rebuild the whole image. If the COPY line came second then it would use the cached RUN layer from the previous build and then only rebuild the COPY layer.\n\n\n\n\n\n\n\n\nExercise: Did it work?\n\n\n\nCan you remember how to run a container interactively? Try that with this one. Once inside, try running the Python script.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nYou can start the container interactively like so:\ndocker container run -it alice/alpine-sum sh\nYou should be able to run the python command inside the container like this:\n/# python3 /home/sum.py\n\n\n\nThis COPY keyword can be used to place your own scripts or own data into a container image that you want to publish or use as a record. Note that it’s not necessarily a good idea to put your scripts inside the container image if you’re constantly changing or editing them. Then, referencing the scripts from outside the container is a good idea, as we did in the previous section. You also want to think carefully about size – if you run docker image ls you’ll see the size of each container image all the way on the right of the screen. The bigger your container image becomes, the harder it will be to easily download.\n\n\n\n\n\n\nSecurity Warning\n\n\n\nLogin credentials including passwords, tokens, secure access tokens or other secrets must never be stored in a container. If secrets are stored, they are at high risk to be found and exploited when made public.\n\n\n\n\n\n\n\n\nCopying alternatives\n\n\n\nAnother trick for getting your own files into a container image is by using the RUN keyword and downloading the files from the internet. For example, if your code is in a GitHub repository, you could include this statement in your Dockerfile to download the latest version every time you build the container image:\nRUN git clone https://github.com/alice/mycode\nSimilarly, the wget command can be used to download any file publicly available on the internet:\nRUN wget ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/2.10.0/ncbi-blast-2.10.0+-x64-linux.tar.gz\nNote that the above RUN examples depend on commands (git and wget respectively) that must be available within your container: Linux distributions such as Alpine may require you to install such commands before using them within RUN statements."
  },
  {
    "objectID": "episodes/07-advanced-containers.html#more-fancy-dockerfile-options-optional-for-presentation-or-as-exercises",
    "href": "episodes/07-advanced-containers.html#more-fancy-dockerfile-options-optional-for-presentation-or-as-exercises",
    "title": "Creating More Complex Container Images",
    "section": "More fancy Dockerfile options (optional, for presentation or as exercises)",
    "text": "More fancy Dockerfile options (optional, for presentation or as exercises)\nWe can expand on the example above to make our container image even more “automatic”. Here are some ideas:\n\nMake the sum.py script run automatically\nFROM alpine\nRUN apk add --update python3 py3-pip python3-dev\nCOPY sum.py /home\n\n# Run the sum.py script as the default command\nCMD [\"python3\", \"/home/sum.py\"]\nBuild and test it:\ndocker image build -t alpine-sum:v1 .\ndocker container run alpine-sum:v1\nYou’ll notice that you can run the container without arguments just fine, resulting in sum = 0, but this is boring. Supplying arguments however doesn’t work:\ndocker container run alpine-sum:v1 10 11 12\nresults in\ndocker: Error response from daemon: OCI runtime create failed:\ncontainer_linux.go:349: starting container process caused \"exec:\n\\\"10\\\": executable file not found in $PATH\": unknown.\nThis is because the arguments 10 11 12 are interpreted as a command that replaces the default command given by CMD [\"python3\", \"/home/sum.py\"] in the image.\nTo achieve the goal of having a command that always runs when a container is run from the container image and can be passed the arguments given on the command line, use the keyword ENTRYPOINT in the Dockerfile.\nFROM alpine\n\nRUN apk add --update python3 py3-pip python3-dev\nCOPY sum.py /home\n\n# Run the sum.py script as the default command and\n# allow people to enter arguments for it\nENTRYPOINT [\"python3\", \"/home/sum.py\"]\n\n# Give default arguments, in case none are supplied on\n# the command-line\nCMD [\"10\", \"11\"]\nBuild and test it:\ndocker image build -t alpine-sum:v2 .\n# Most of the time you are interested in the sum of 10 and 11:\ndocker container run alpine-sum:v2\n# Sometimes you have more challenging calculations to do:\ndocker container run alpine-sum:v2 12 13 14\n\n\n\n\n\n\nOverriding the ENTRYPOINT\n\n\n\nSometimes you don’t want to run the image’s ENTRYPOINT. For example if you have a specialized container image that does only sums, but you need an interactive shell to examine the container:\ndocker container run -it alpine-sum:v2 /bin/sh\nwill yield\nPlease supply integer arguments\nYou need to override the ENTRYPOINT statement in the container image like so:\ndocker container run -it --entrypoint /bin/sh alpine-sum:v2\n\n\n\n\nAdd the sum.py script to the PATH so you can run it directly:\nFROM alpine\n\nRUN apk add --update python3 py3-pip python3-dev\n\nCOPY sum.py /home\n# set script permissions\nRUN chmod +x /home/sum.py\n# add /home folder to the PATH\nENV PATH /home:$PATH\nBuild and test it:\ndocker image build -t alpine-sum:v3 .\ndocker container run alpine-sum:v3 sum.py 1 2 3 4\n\n\n\n\n\n\nBest practices for writing Dockerfiles\n\n\n\nTake a look at Nüst et al.’s “Ten simple rules for writing Dockerfiles for reproducible data science” [1] for some great examples of best practices to use when writing Dockerfiles. The GitHub repository associated with the paper also has a set of example Dockerfiles demonstrating how the rules highlighted by the paper can be applied.\n[1] Nüst D, Sochat V, Marwick B, Eglen SJ, Head T, et al. (2020) Ten simple rules for writing Dockerfiles for reproducible data science. PLOS Computational Biology 16(11): e1008316. https://doi.org/10.1371/journal.pcbi.1008316\n\n\n\n\n\n\n\n\nKey Points\n\n\n\n\nDocker allows containers to read and write files from the Docker host.\nYou can include files from your Docker host into your Docker container images by using the COPY instruction in your Dockerfile.\n\n\n\n\n\n\n← Previous\n\n\nNext →"
  },
  {
    "objectID": "episodes/06-creating-container-images.html",
    "href": "episodes/06-creating-container-images.html",
    "title": "Creating Your Own Container Images",
    "section": "",
    "text": "Overview\n\n\n\n\nTeaching: 20\nExercises: 15\nQuestions:\n\nHow can I make my own Docker container images?\nHow do I document the ‘recipe’ for a Docker container image?\n\nObjectives:\n\nExplain the purpose of a Dockerfile and show some simple examples.\nDemonstrate how to build a Docker container image from a Dockerfile.\nCompare the steps of creating a container image interactively versus a Dockerfile.\nCreate an installation strategy for a container image.\nDemonstrate how to upload (‘push’) your container images to the Docker Hub.\nDescribe the significance of the Docker Hub naming scheme.\nThere are lots of reasons why you might want to create your own Docker container image."
  },
  {
    "objectID": "episodes/06-creating-container-images.html#interactive-installation",
    "href": "episodes/06-creating-container-images.html#interactive-installation",
    "title": "Creating Your Own Container Images",
    "section": "Interactive installation",
    "text": "Interactive installation\nBefore creating a reproducible installation, let’s experiment with installing software inside a container. Start a container from the alpine container image we used before, interactively:\ndocker container run -it alpine sh\nBecause this is a basic container, there’s a lot of things not installed – for example, python3.\n/# python3\nsh: python3: not found\nInside the container, we can run commands to install Python 3. The Alpine version of Linux has a installation tool called apk that we can use to install Python 3.\n/# apk add --update python3 py3-pip python3-dev\nWe can test our installation by running a Python command:\n/# python3 --version\n\n\n\n\n\n\nExercise: Searching for Help\n\n\n\nCan you find instructions for installing R on Alpine Linux? Do they work?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nA quick search should hopefully show that the way to install R on Alpine Linux is:\n/# apk add R\n\n\n\nOnce we exit, these changes are not saved to a new container image by default. There is a command that will “snapshot” our changes, but building container images this way is not easily reproducible. Instead, we’re going to take what we’ve learned from this interactive installation and create our container image from a reproducible recipe, known as a Dockerfile.\nIf you haven’t already, exit out of the interactively running container.\n/# exit"
  },
  {
    "objectID": "episodes/06-creating-container-images.html#put-installation-instructions-in-a-dockerfile",
    "href": "episodes/06-creating-container-images.html#put-installation-instructions-in-a-dockerfile",
    "title": "Creating Your Own Container Images",
    "section": "Put installation instructions in a Dockerfile",
    "text": "Put installation instructions in a Dockerfile\nA Dockerfile is a plain text file with keywords and commands that can be used to create a new container image.\nFrom your shell, go to the folder you downloaded at the start of the lesson and print out the Dockerfile inside:\ncd ~/Desktop/docker-intro/basic\ncat Dockerfile\nFROM &lt;EXISTING IMAGE&gt;\nRUN &lt;INSTALL CMDS FROM SHELL&gt;\nCMD &lt;CMD TO RUN BY DEFAULT&gt;\nLet’s break this file down:\n\nThe first line, FROM, indicates which container image we’re starting with. It is the “base” container image we are going to start from.\nThe next two lines RUN, will indicate installation commands we want to run. These are the same commands that we used interactively above.\nThe last line, CMD, indicates the default command we want a container based on this container image to run, if no other command is provided. It is recommended to provide CMD in exec-form (see the CMD section of the Dockerfile documentation for more details). It is written as a list which contains the executable to run as its first element, optionally followed by any arguments as subsequent elements. The list is enclosed in square brackets ([]) and its elements are double-quoted (\") strings which are separated by commas. For example, CMD [\"ls\", \"-lF\", \"--color\", \"/etc\"] would translate to ls -lF --color /etc.\n\n\n\n\n\n\n\nshell-form and exec-form for CMD\n\n\n\nAnother way to specify the parameter for the CMD instruction is the shell-form. Here you type the command as you would call it from the command line. Docker then silently runs this command in the image’s standard shell. CMD cat /etc/passwd is equivalent to CMD [\"/bin/sh\", \"-c\", \"cat /etc/passwd\"]. We recommend to prefer the more explicit exec-form because we will be able to create more flexible container image command options and make sure complex commands are unambiguous in this format.\n\n\n\n\n\n\n\n\nExercise: Take a Guess\n\n\n\nDo you have any ideas about what we should use to fill in the sample Dockerfile to replicate the installation we did above?\n\n\n\n\n\n\n\n\nSolution:\n\n\n\n\n\nBased on our experience above, edit the Dockerfile (in your text editor of choice) to look like this:\nFROM alpine\nRUN apk add --update python3 py3-pip python3-dev\nCMD [\"python3\", \"--version\"]\n\n\n\nThe recipe provided by the Dockerfile shown in the solution to the preceding exercise will use Alpine Linux as the base container image, add Python 3, the pip package management tool and some additional Python header files, and set a default command to request Python 3 to report its version information."
  },
  {
    "objectID": "episodes/06-creating-container-images.html#create-a-new-docker-image",
    "href": "episodes/06-creating-container-images.html#create-a-new-docker-image",
    "title": "Creating Your Own Container Images",
    "section": "Create a new Docker image",
    "text": "Create a new Docker image\nSo far, we only have a text file named Dockerfile – we do not yet have a container image. We want Docker to take this Dockerfile, run the installation commands contained within it, and then save the resulting container as a new container image. To do this we will use the docker image build command.\nWe have to provide docker image build with two pieces of information:\n\nthe location of the Dockerfile\nthe name of the new container image. Remember the naming scheme from before? You should name your new image with your Docker Hub username and a name for the container image, like this: USERNAME/CONTAINER_IMAGE_NAME.\n\nAll together, the build command that you should run on your computer, will have a similar structure to this:\ndocker image build -t USERNAME/CONTAINER_IMAGE_NAME .\nThe -t option names the container image; the final dot indicates that the Dockerfile is in our current directory.\nFor example, if my user name was alice and I wanted to call my container image alpine-python, I would use this command:\ndocker image build -t alice/alpine-python .\n\n\n\n\n\n\nBuild Context\n\n\n\nNotice that the final input to docker image build isn’t the Dockerfile – it’s a directory! In the command above, we’ve used the current working directory (.) of the shell as the final input to the docker image build command. This option provides what is called the build context to Docker – if there are files being copied into the built container image more details in the next episode they’re assumed to be in this location. Docker expects to see a Dockerfile in the build context also (unless you tell it to look elsewhere).\nEven if it won’t need all of the files in the build context directory, Docker does “load” them before starting to build, which means that it’s a good idea to have only what you need for the container image in a build context directory, as we’ve done in this example.\n\n\n\n\n\n\n\n\nExercise: Review!\n\n\n\n\nThink back to earlier. What command can you run to check if your container image was created successfully? (Hint: what command shows the container images on your computer?)\nWe didn’t specify a tag for our container image name. What tag did Docker automatically use?\nWhat command will run a container based on the container image you’ve created? What should happen by default if you run such a container? Can you make it do something different, like print “hello world”?\n\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nTo see your new image, run docker image ls. You should see the name of your new container image under the “REPOSITORY” heading.\nIn the output of docker image ls, you can see that Docker has automatically used the latest tag for our new container image.\nWe want to use docker container run to run a container based on a container image.\n\nThe following command should run a container and print out our default message, the version of Python:\ndocker container run alice/alpine-python\nTo run a container based on our container image and print out “Hello world” instead:\ndocker container run alice/alpine-python echo \"Hello World\"\n\n\n\nWhile it may not look like you have achieved much, you have already effected the combination of a lightweight Linux operating system with your specification to run a given command that can operate reliably on macOS, Microsoft Windows, Linux and on the cloud!"
  },
  {
    "objectID": "episodes/06-creating-container-images.html#boring-but-important-notes-about-installation",
    "href": "episodes/06-creating-container-images.html#boring-but-important-notes-about-installation",
    "title": "Creating Your Own Container Images",
    "section": "Boring but important notes about installation",
    "text": "Boring but important notes about installation\nThere are a lot of choices when it comes to installing software – sometimes too many! Here are some things to consider when creating your own container image:\n\nStart smart, or, don’t install everything from scratch! If you’re using Python as your main tool, start with a Python container image. Same with the R programming language. We’ve used Alpine Linux as an example in this lesson, but it’s generally not a good container image to start with for initial development and experimentation because it is a less common distribution of Linux; using Ubuntu, Debian and CentOS are all good options for scientific software installations. The program you’re using might recommend a particular distribution of Linux, and if so, it may be useful to start with a container image for that distribution.\nHow big? How much software do you really need to install? When you have a choice, lean towards using smaller starting container images and installing only what’s needed for your software, as a bigger container image means longer download times to use.\nKnow (or Google) your Linux. Different distributions of Linux often have distinct sets of tools for installing software. The apk command we used above is the software package installer for Alpine Linux. The installers for various common Linux distributions are listed below:\n\nUbuntu: apt or apt-get\nDebian: deb\nCentOS: yum Most common software installations are available to be installed via these tools. A web search for “install X on Y Linux” is usually a good start for common software installation tasks; if something isn’t available via the Linux distribution’s installation tools, try the options below.\n\nUse what you know. You’ve probably used commands like pip or install.packages() before on your own computer – these will also work to install things in container images (if the basic scripting language is installed).\nREADME. Many scientific software tools have a README or installation instructions that lay out how to install software. You want to look for instructions for Linux. If the install instructions include options like those suggested above, try those first.\n\nIn general, a good strategy for installing software is:\n\nMake a list of what you want to install.\nLook for pre-existing container images.\nRead through instructions for software you’ll need to install.\nTry installing everything interactively in your base container – take notes!\nFrom your interactive installation, create a Dockerfile and then try to build the container image from that."
  },
  {
    "objectID": "episodes/06-creating-container-images.html#share-your-new-container-image-on-docker-hub",
    "href": "episodes/06-creating-container-images.html#share-your-new-container-image-on-docker-hub",
    "title": "Creating Your Own Container Images",
    "section": "Share your new container image on Docker Hub",
    "text": "Share your new container image on Docker Hub\nContainer images that you release publicly can be stored on the Docker Hub for free. If you name your container image as described above, with your Docker Hub username, all you need to do is run the opposite of docker image pull – docker image push.\ndocker image push alice/alpine-python\nMake sure to substitute the full name of your container image!\nIn a web browser, open https://hub.docker.com, and on your user page you should now see your container image listed, for anyone to use or build on.\n\n\n\n\n\n\nLogging In\n\n\n\nTechnically, you have to be logged into Docker on your computer for this to work. Usually it happens by default, but if docker image push doesn’t work for you, run docker login first, enter your Docker Hub username and password, and then try docker image push again."
  },
  {
    "objectID": "episodes/06-creating-container-images.html#whats-in-a-name-again",
    "href": "episodes/06-creating-container-images.html#whats-in-a-name-again",
    "title": "Creating Your Own Container Images",
    "section": "What’s in a name? (again)",
    "text": "What’s in a name? (again)\nYou don’t have to name your containers images using the USERNAME/CONTAINER_IMAGE_NAME:TAG naming scheme. On your own computer, you can call container images whatever you want, and refer to them by the names you choose. It’s only when you want to share a container image that it needs the correct naming format.\nYou can rename container images using the docker image tag command. For example, imagine someone named Alice has been working on a workflow container image and called it workflow-test on her own computer. She now wants to share it in her alice Docker Hub account with the name workflow-complete and a tag of v1. Her docker image tag command would look like this:\ndocker image tag workflow-test alice/workflow-complete:v1\nShe could then push the re-named container image to Docker Hub, using docker image push alice/workflow-complete:v1\n\n\n\n\n\n\nKey Points\n\n\n\n\nDockerfiles specify what is within Docker container images.\nThe docker image build command is used to build a container image from a Dockerfile.\nYou can share your Docker container images through the Docker Hub so that others can create Docker containers from your container images.\n\n\n\n\n\n\n← Previous\n\n\nNext →"
  },
  {
    "objectID": "episodes/02-meet-docker.html",
    "href": "episodes/02-meet-docker.html",
    "title": "Introducing the Docker Command Line",
    "section": "",
    "text": "Overview\n\n\n\n\nTeaching: 10\nExercises: 5\nQuestions:\n\nHow do I know Docker is installed and running?\nHow do I interact with Docker?\n\nObjectives:\n\nExplain how to check that Docker is installed and is ready to use.\nDemonstrate some initial Docker command line interactions.\nUse the built-in help for Docker commands."
  },
  {
    "objectID": "episodes/02-meet-docker.html#docker-command-line",
    "href": "episodes/02-meet-docker.html#docker-command-line",
    "title": "Introducing the Docker Command Line",
    "section": "Docker command line",
    "text": "Docker command line\nStart the Docker application that you installed in working through the setup instructions for this session. Note that this might not be necessary if your laptop is running Linux or if the installation added the Docker application to your startup process.\n\n\n\n\n\n\nYou may need to login to Docker Hub\n\n\n\nThe Docker application will usually provide a way for you to log in to the Docker Hub using the application’s menu (macOS) or systray icon (Windows) and it is usually convenient to do this when the application starts. This will require you to use your Docker Hub username and your password. We will not actually require access to the Docker Hub until later in the course but if you can login now, you should do so.\n\n\n\n\n\n\n\n\nDetermining your Docker Hub username\n\n\n\nIf you no longer recall your Docker Hub username, e.g., because you have been logging into the Docker Hub using your email address, you can find out what it is through the steps:\n\nOpen https://hub.docker.com/ in a web browser window\nSign-in using your email and password (don’t tell us what it is)\nIn the top-right of the screen you will see your username\n\n\n\nOnce your Docker application is running, open a shell (terminal) window, and run the following command to check that Docker is installed and the command line tools are working correctly. Below is the output for a Mac version, but the specific version is unlikely to matter much: it does not have to precisely match the one listed below.\ndocker --version\nDocker version 20.10.5, build 55c4c88\nThe above command has not actually relied on the part of Docker that runs containers, just that Docker is installed and you can access it correctly from the command line.\nA command that checks that Docker is working correctly is the docker container ls command (we cover this command in more detail later in the course).\nWithout explaining the details, output on a newly installed system would likely be:\ndocker container ls\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\n(The command docker system info could also be used to verify that Docker is correctly installed and operational but it produces a larger amount of output.)\nHowever, if you instead get a message similar to the following\nCannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\nthen you need to check that you have started the Docker Desktop, Docker Engine, or however else you worked through the setup instructions."
  },
  {
    "objectID": "episodes/02-meet-docker.html#getting-help",
    "href": "episodes/02-meet-docker.html#getting-help",
    "title": "Introducing the Docker Command Line",
    "section": "Getting help",
    "text": "Getting help\nOften when working with a new command line tool, we need to get help. These tools often have some sort of subcommand or flag (usually help, -h, or --help) that displays a prompt describing how to use the tool. For Docker, it’s no different. If we run docker --help, we see the following output (running docker also produces the help message):\n\nUsage:  docker [OPTIONS] COMMAND\n\nA self-sufficient runtime for containers\n\nOptions:\n      --config string      Location of client config files (default \"/Users/vini/.docker\")\n  -c, --context string     Name of the context to use to connect to the daemon (overrides DOCKER_HOST env var and default context set with \"docker context use\")\n  -D, --debug              Enable debug mode\n  -H, --host list          Daemon socket(s) to connect to\n  -l, --log-level string   Set the logging level (\"debug\"|\"info\"|\"warn\"|\"error\"|\"fatal\") (default \"info\")\n      --tls                Use TLS; implied by --tlsverify\n      --tlscacert string   Trust certs signed only by this CA (default \"/Users/vini/.docker/ca.pem\")\n      --tlscert string     Path to TLS certificate file (default \"/Users/vini/.docker/cert.pem\")\n      --tlskey string      Path to TLS key file (default \"/Users/vini/.docker/key.pem\")\n      --tlsverify          Use TLS and verify the remote\n  -v, --version            Print version information and quit\n\nManagement Commands:\n  app*        Docker App (Docker Inc., v0.9.1-beta3)\n  builder     Manage builds\n  buildx*     Build with BuildKit (Docker Inc., v0.5.1-docker)\n  config      Manage Docker configs\n  container   Manage containers\n  context     Manage contexts\n  image       Manage images\n  manifest    Manage Docker image manifests and manifest lists\n  network     Manage networks\n  node        Manage Swarm nodes\n  plugin      Manage plugins\n  scan*       Docker Scan (Docker Inc., v0.6.0)\n  secret      Manage Docker secrets\n  service     Manage services\n  stack       Manage Docker stacks\n  swarm       Manage Swarm\n  system      Manage Docker\n  trust       Manage trust on Docker images\n  volume      Manage volumes\n\nCommands:\n  attach      Attach local standard input, output, and error streams to a running container\n  build       Build an image from a Dockerfile\n  commit      Create a new image from a container's changes\n  cp          Copy files/folders between a container and the local filesystem\n  create      Create a new container\n  diff        Inspect changes to files or directories on a container's filesystem\n  events      Get real time events from the server\n  exec        Run a command in a running container\n  export      Export a container's filesystem as a tar archive\n  history     Show the history of an image\n  images      List images\n  import      Import the contents from a tarball to create a filesystem image\n  info        Display system-wide information\n  inspect     Return low-level information on Docker objects\n  kill        Kill one or more running containers\n  load        Load an image from a tar archive or STDIN\n  login       Log in to a Docker registry\n  logout      Log out from a Docker registry\n  logs        Fetch the logs of a container\n  pause       Pause all processes within one or more containers\n  port        List port mappings or a specific mapping for the container\n  ps          List containers\n  pull        Pull an image or a repository from a registry\n  push        Push an image or a repository to a registry\n  rename      Rename a container\n  restart     Restart one or more containers\n  rm          Remove one or more containers\n  rmi         Remove one or more images\n  run         Run a command in a new container\n  save        Save one or more images to a tar archive (streamed to STDOUT by default)\n  search      Search the Docker Hub for images\n  start       Start one or more stopped containers\n  stats       Display a live stream of container(s) resource usage statistics\n  stop        Stop one or more running containers\n  tag         Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE\n  top         Display the running processes of a container\n  unpause     Unpause all processes within one or more containers\n  update      Update configuration of one or more containers\n  version     Show the Docker version information\n  wait        Block until one or more containers stop, then print their exit codes\n\nRun 'docker COMMAND --help' for more information on a command.\nThere is a list of commands and the end of the help message says: Run 'docker COMMAND --help' for more information on a command. For example, take the docker container ls command that we ran previously. We can see from the Docker help prompt that container is a Docker command, so to get help for that command, we run:\ndocker container --help  # or instead 'docker container'\n\nUsage:  docker container COMMAND\n\nManage containers\n\nCommands:\n  attach      Attach local standard input, output, and error streams to a running container\n  commit      Create a new image from a container's changes\n  cp          Copy files/folders between a container and the local filesystem\n  create      Create a new container\n  diff        Inspect changes to files or directories on a container's filesystem\n  exec        Run a command in a running container\n  export      Export a container's filesystem as a tar archive\n  inspect     Display detailed information on one or more containers\n  kill        Kill one or more running containers\n  logs        Fetch the logs of a container\n  ls          List containers\n  pause       Pause all processes within one or more containers\n  port        List port mappings or a specific mapping for the container\n  prune       Remove all stopped containers\n  rename      Rename a container\n  restart     Restart one or more containers\n  rm          Remove one or more containers\n  run         Run a command in a new container\n  start       Start one or more stopped containers\n  stats       Display a live stream of container(s) resource usage statistics\n  stop        Stop one or more running containers\n  top         Display the running processes of a container\n  unpause     Unpause all processes within one or more containers\n  update      Update configuration of one or more containers\n  wait        Block until one or more containers stop, then print their exit codes\n\nRun 'docker container COMMAND --help' for more information on a command.\nThere’s also help for the container ls command:\ndocker container ls --help  # this one actually requires the '--help' flag\nUsage:  docker container ls [OPTIONS]\n\nList containers\n\nAliases:\n  ls, ps, list\n\nOptions:\n  -a, --all             Show all containers (default shows just running)\n  -f, --filter filter   Filter output based on conditions provided\n      --format string   Pretty-print containers using a Go template\n  -n, --last int        Show n last created containers (includes all states) (default -1)\n  -l, --latest          Show the latest created container (includes all states)\n      --no-trunc        Don't truncate output\n  -q, --quiet           Only display container IDs\n  -s, --size            Display total file sizes\nYou may notice that there are many commands that stem from the docker command. Instead of trying to remember all possible commands and options, it’s better to learn how to effectively get help from the command line. Although we can always search the web, getting the built-in help from our tool is often much faster and may provide the answer right away. This applies not only to Docker, but also to most command line-based tools.\n\n\n\n\n\n\nDocker Command Line Interface (CLI) syntax\n\n\n\nIn this lesson we use the newest Docker CLI syntax introduced with the Docker Engine version 1.13. This new syntax combines commands into groups you will most often want to interact with. In the help example above you can see image and container management commands, which can be used to interact with your images and containers respectively. With this new syntax you issue commands using the following pattern docker [command] [subcommand] [additional options]\nComparing the output of two help commands above, you can see that the same thing can be achieved in multiple ways. For example to start a Docker container using the old syntax you would use docker run. To achieve the same with the new syntax, you use docker container run instead. Even though the old approach is shorter and still officially supported, the new syntax is more descriptive, less error-prone and is therefore recommended.\n\n\n\n\n\n\n\n\nExploring a command\n\n\n\nRun docker --help and pick a command from the list. Explore the help prompt for that command. Try to guess how a command would work by looking at the Usage: section of the prompt.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nSuppose we pick the docker image build command:\ndocker image build --help\nUsage:  docker image build [OPTIONS] PATH | URL | -\n\nBuild an image from a Dockerfile\n\nOptions:\n     --add-host list           Add a custom host-to-IP mapping (host:ip)\n     --build-arg list          Set build-time variables\n     --cache-from strings      Images to consider as cache sources\n     --cgroup-parent string    Optional parent cgroup for the container\n     --compress                Compress the build context using gzip\n     --cpu-period int          Limit the CPU CFS (Completely Fair Scheduler) period\n     --cpu-quota int           Limit the CPU CFS (Completely Fair Scheduler) quota\n -c, --cpu-shares int          CPU shares (relative weight)\n     --cpuset-cpus string      CPUs in which to allow execution (0-3, 0,1)\n     --cpuset-mems string      MEMs in which to allow execution (0-3, 0,1)\n     --disable-content-trust   Skip image verification (default true)\n -f, --file string             Name of the Dockerfile (Default is 'PATH/Dockerfile')\n     --force-rm                Always remove intermediate containers\n     --iidfile string          Write the image ID to the file\n     --isolation string        Container isolation technology\n     --label list              Set metadata for an image\n -m, --memory bytes            Memory limit\n     --memory-swap bytes       Swap limit equal to memory plus swap: '-1' to enable unlimited swap\n     --network string          Set the networking mode for the RUN instructions during build (default \"default\")\n     --no-cache                Do not use cache when building the image\n     --pull                    Always attempt to pull a newer version of the image\n -q, --quiet                   Suppress the build output and print image ID on success\n     --rm                      Remove intermediate containers after a successful build (default true)\n     --security-opt strings    Security options\n     --shm-size bytes          Size of /dev/shm\n -t, --tag list                Name and optionally a tag in the 'name:tag' format\n     --target string           Set the target build stage to build.\n     --ulimit ulimit           Ulimit options (default [])\nWe could try to guess that the command could be run like this:\ndocker image build .\nor\ndocker image build https://github.com/docker/rootfs.git\nWhere https://github.com/docker/rootfs.git could be any relevant URL that supports a Docker image.\n\n\n\n\n\n\n\n\n\nKey Points\n\n\n\n\nA toolbar icon indicates that Docker is ready to use (on Windows and macOS).\nYou will typically interact with Docker using the command line.\nTo learn how to run a certain Docker command, we can type the command followed by the --help flag.\n\n\n\n\n\n\n← Previous\n\n\nNext →"
  }
]